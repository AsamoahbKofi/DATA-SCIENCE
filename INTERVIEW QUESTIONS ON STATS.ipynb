{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8ef99e0-4f57-44f8-8af3-6eada7c1ba32",
   "metadata": {},
   "source": [
    "# 1.What is central limit theorm and what're their significance in statistics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc374929-6362-492d-ad5c-448bf3d5e7c1",
   "metadata": {},
   "source": [
    "CLT: Here's an overview,the idea of central limit theorm is that when we pick samples from different population,\n",
    "and calculate their means, those means will be normally distributed regardless of the shape of the original population\n",
    "significance: allows statisticians to make inference on data\n",
    "it also allows statisticians to identify behaviour of samples in a population\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6499cc6-6fc0-4d8b-bdd5-2548266bd27f",
   "metadata": {},
   "source": [
    "# 2.Differnce between type I and typr II error, give examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aced86c-12de-4cf2-a3b7-898ff35f59d0",
   "metadata": {},
   "source": [
    "Type I error: Inorrecting rejecting the null hypothesis when it's actuallly correct or true\n",
    "Example: Medical test on patient\n",
    "null hpothesis: He does not have the disease\n",
    "alternate hypothese: He has the disease\n",
    "type I error: Incorrectly concluding that he has the disease when he doesn't have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb8b7f5-df5d-483b-ac57-2ffdee65497b",
   "metadata": {},
   "source": [
    "Type II error: Inorrecting accepting the null hypothesis when it's false\n",
    "Example: Medical test on patient\n",
    "null hpothesis: He does not have the disease\n",
    "alternate hypothese: He has the disease\n",
    "type I error: Incorrectly concluding that he has the disease when he doesn't have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5d8059-7e5a-4acf-aa95-7d852a7cc4f0",
   "metadata": {},
   "source": [
    "Example:\n",
    "Type I Error: Sending a healthy person to further medical treatment.\n",
    "Type II Error: Failing to identify a diseased person who needs medical attention."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6229954a-14b4-4472-94ff-69f2bf7da9ae",
   "metadata": {},
   "source": [
    "# 3.Define p value, how is it used in hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae6afed-503c-43f2-bef0-b067c3234f32",
   "metadata": {},
   "source": [
    "p-value provides a way to assess the strength of evidence against the null hypothesis in hypothesis testing\n",
    "when p-value<significant level , we reject the null hypothesis (statistically significant)\n",
    "when p-value>significant level , we fail to reject the null hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8768954d-a157-4d7f-a204-bb21d0412f15",
   "metadata": {},
   "source": [
    "\n",
    "\"Statistically significant\" refers to the outcome of a statistical test where the results are \n",
    "\n",
    "unlikely to have occurred by chance alone. In other words, when a finding is deemed statistically significant,\n",
    "\n",
    "it suggests that there is strong evidence against the null hypothesis,\n",
    "\n",
    "and the observed results are likely to reflect a true effect or relationship in the population being studied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09394336-1a01-4898-a408-419743f035fa",
   "metadata": {},
   "source": [
    "# 4.Describe the concept of bayesian inference and state their implications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683faad4-07f3-4976-bdd9-bab6d1fecbcb",
   "metadata": {},
   "source": [
    "Bayesian inference is a statistical framework for making predictions about uncertain quantities based on both prior knowledge and observed data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a7db36-1dd2-474b-a8c8-f9a2587a1e2f",
   "metadata": {},
   "source": [
    "# Multicollinearity refers to a situation in which two or more predictor variables in \n",
    "\n",
    "a regression model are highly correlated with each other.\n",
    "\n",
    "In other words, it occurs when there is a strong linear relationship between independent variables,\n",
    "\n",
    "making it difficult for the model to differentiate the individual effects of each predictor variable on the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a452d8-c370-4e7b-9c62-c09782776ad8",
   "metadata": {},
   "source": [
    "# 5.Difference between parametric and non parametric statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4606215-8064-4451-bc2a-56b13b1d8684",
   "metadata": {},
   "source": [
    "Parametric statistics assume that the data are drawn from a specific probability distribution\n",
    "\n",
    "with known parameters (e.g., normal distribution, binomial distribution).\n",
    "\n",
    "These methods require knowledge of the population parameters (e.g., mean, variance)\n",
    "\n",
    "or assume a specific distribution for the data.\n",
    "\n",
    "Parametric methods include t-tests, analysis of variance (ANOVA), linear regression,\n",
    "\n",
    "logistic regression, and chi-square tests for goodness of fit and independence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6305f60-03a5-417c-8f49-2aa882820fb4",
   "metadata": {},
   "source": [
    "Assumptions:\n",
    "\n",
    "Nonparametric statistics make fewer assumptions about the underlying distribution of the data.\n",
    "\n",
    "They do not require knowledge of population parameters or assume a specific distribution for the data.\n",
    "Examples:\n",
    "Nonparametric methods include Wilcoxon rank-sum test, Mann-Whitney U test, Kruskal-Wallis test,\n",
    "                                                                                        \n",
    "Spearman's rank correlation coefficient, and Friedman test.                                                                                        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcccd884-d448-4604-8c43-0fed043a5929",
   "metadata": {},
   "source": [
    "Discuss the purpose and intrepretation of confidence intervals*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7114f1-88d9-4831-909c-a34901e8ce5d",
   "metadata": {},
   "source": [
    "# 6.Confidence intervals (CIs)\n",
    "\n",
    "are a fundamental tool in statistics used to estimate the range of plausible values for\n",
    "                                                                                                              \n",
    "a population parameter,such as the mean, proportion, or regression coefficient. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67747679-3c2e-47df-9606-011a7d73eec3",
   "metadata": {},
   "source": [
    "# 7.What is Linear Regression?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2da3aa-1eee-4444-a9da-ce81a31e8d69",
   "metadata": {},
   "source": [
    "Linear regression is a statistical analyisis or machine learning algorithm that tends to find relationship \n",
    "\n",
    "between dependant variables and indepedent variables using line of best fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5278d119-fd86-4d6e-b95a-116b3617caaa",
   "metadata": {},
   "source": [
    "# 8.What is L1 Regularization (L1 = lasso) ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5e6b28-da46-4640-9944-8e072705125c",
   "metadata": {},
   "source": [
    "L1 regularization is a regularization technique that aims to reduce overfitting as\n",
    "\n",
    "they add penalty(abs value) to the loss function.\n",
    "    \n",
    "Lasso regression shrinks the less important features to zero ,thus elimating the less important features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdc8424-3646-47fa-80c8-1e02fdb69c41",
   "metadata": {},
   "source": [
    "# 9.L2 Regularization(L2 = Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84e0384-e1c6-44fc-b9a5-6f11320f1a53",
   "metadata": {},
   "source": [
    " L2 regularization is a regularization technique that aims to reduce overfitting as\n",
    "\n",
    "they add penalty(sqrt value) to the loss function.\n",
    "\n",
    "Ridge regression aims at penalizing large co-efficients\n",
    "\n",
    "Ridge is not robust to outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c0b926-0c9a-4a4d-9cb9-64bba116010c",
   "metadata": {},
   "source": [
    "# 10. What is R square(where to use and where not)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441e0808-d118-4e1d-b235-b48bbe733684",
   "metadata": {},
   "source": [
    "R-square refers to how close the data are to the fitted line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b045f66-c9c4-429b-93ed-a24f4e7cfc2d",
   "metadata": {},
   "source": [
    "# 11.Adjusted R-Square"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab311da-ff80-44eb-824a-683a944903c5",
   "metadata": {},
   "source": [
    "Is a regression meteric that aims to penalize less/unwanted independent variable from the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c93aeb8-7a74-4d3f-9924-64cb59b9c9d6",
   "metadata": {},
   "source": [
    "# 12.What is Mean Square Error?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bcffd3-3c6b-4000-bd65-796623b08c31",
   "metadata": {},
   "source": [
    "The mean squared error tells you how close a regression line is to a set of points.It does this by \n",
    "\n",
    "taking the distances from the points to the regression line (these distances are the “errors”) and \n",
    "\n",
    "squaring them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73426de-d488-41c2-9972-55321ffbb263",
   "metadata": {},
   "source": [
    "# 13.Why Support Vector Regression? Difference between SVR and a simple regression \n",
    "model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc41564-8399-4d8e-9c8d-aa1d27344b69",
   "metadata": {},
   "source": [
    "# 14.What is Variance and Bias tradeoff?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5abbfb1-0a92-4c78-945c-e9f457dd2686",
   "metadata": {},
   "source": [
    "In predicting models, the prediction error is composed of two different errors\n",
    "1. Bias\n",
    "2. Variance\n",
    "bias is something which measures how far these model prediction \n",
    "from the correct prediction.\n",
    "    \n",
    "variance is how much the predictions for a given point vary between different \n",
    "realizations of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eefb757-127f-49cc-b7d0-4f7171e0899a",
   "metadata": {},
   "source": [
    "# 15.What are Ensemble Methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b92a3ba-3b6c-4309-8cde-33ab027f810f",
   "metadata": {},
   "source": [
    "Ensemble methods - which combines several decision trees to produce better predictive \n",
    "This is done by averaging predictions from different models like bagging,bosoting tec\n",
    "performance than utilizing a single decision tree. The main principle behind the ensemble model is \n",
    "that a group of weak learners come together to form a strong learner.\n",
    "Two techniques to perform ensemble decision trees:\n",
    "1. Bagging\n",
    "2. Boosting\n",
    "\n",
    "Bagging (Bootstrap Aggregation) is used when our goal is to reduce the variance of a decision tree. \n",
    "Here the idea is to create several subsets of data from the training sample chosen randomly with \n",
    "replacement. Now, each collection of subset data is used to train their decision trees. As a result, we \n",
    "end up with an ensemble of different models. Average of all the predictions from different trees are \n",
    "used which is more robust than a single decision tree.\n",
    "\n",
    "-Training multiple model in parallel\n",
    "-each random training set is random drawn with replacement\n",
    "-final prediction is made by averaging the prediction from all the models\n",
    "reduces overftting and reduces variance also\n",
    "\n",
    "BOOSTING\n",
    "Unlike baggging which trains multiple model independently, boosting sequentially trains series of week learners\n",
    "(models like decision tre),and each subsequent model focuses on samples that previous models have misclassified\n",
    "In boosting , the model pays more attenstion to previously misclassified instances therby improving the overall performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480e4ca4-4fb4-48d3-af09-780c4e2fe1d7",
   "metadata": {},
   "source": [
    "16.skipped SVM,DT,RM,NBC,KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471a774e-c73e-4bd8-ba3b-726effe98e1d",
   "metadata": {},
   "source": [
    "# 17.What is the Confusion Matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee8de15-f4d2-47bf-b4a9-18fde7e98486",
   "metadata": {},
   "source": [
    "A confusion matrix is a table that is often used to describe the performance of a classification model \n",
    "(or “classifier”) on a set of test data\n",
    "It displays the number of correct and incorrectly predictions by the model on a dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4489db45-3148-4643-bf02-31b6f3ab6756",
   "metadata": {},
   "source": [
    "Accuracy:it is used to evaluate the overall peformance of a model: TP+TN/TOTAL*100\n",
    "\n",
    "Misclassification or error rate: is the proportion of incorrect predictions over total predictions\n",
    "\n",
    "FN+FP/Toatl*100\n",
    "\n",
    "True positive rate/Recall/sentitivity: the ability of the model to capture positive instances or\n",
    "\n",
    "the proportion of positive instances that were correctly predicted by the model: TP/TP+FN\n",
    "\n",
    "Specificity: the model's ability to capture negative instances: TN/TN+FP\n",
    "\n",
    "Precision: measure of true positives instances out all the positive predictions: Tp/TP+FP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65921fd9-3486-4283-ae70-a27006a863af",
   "metadata": {},
   "source": [
    "# 18. How do you treat heteroscedasticity in regression?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc990905-aeb2-41c4-a7ab-c8c79512cfe6",
   "metadata": {},
   "source": [
    "Heteroscedasticity in regression occurs when the variablity of the residuals(difference between true and predicted)\n",
    "is not constant across all the independent variables\n",
    "\n",
    "in other words, it occurs when the spread of the residials change as the values of independent variables change\n",
    "\n",
    "it can lead to biased estimate and incorrect inference \n",
    "\n",
    "To address this:\n",
    "Transform variables (log or square roots)\n",
    "Weighted least squared errors\n",
    "Robots standard errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2025bb17-deec-4acf-8e6c-d76d3fc780ab",
   "metadata": {},
   "source": [
    "# 19 What is Epoch\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
